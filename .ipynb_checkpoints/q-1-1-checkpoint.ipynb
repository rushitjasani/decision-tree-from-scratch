{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q-1-1.py\n",
    "\n",
    "Train decision tree only on categorical data. Report precision, recall, f1 score and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS : \n",
    "\n",
    "1. read data\n",
    "2. apply onehot encoding ( to handle categorical Data )\n",
    "3. divide dataset in 80:20 for training and validation.\n",
    "4. build decision tree using build_tree and helper functions for entropy and attribite_to_select etc\n",
    "5. apply predict method to predict class label and use inbuilt functions to calculate confusion matrix, classification report and accuracy score.\n",
    "6. calculate the same measures using inbuilt scikit-learn decision tree to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting features and class label and dropping numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop([ 'number_project', 'left','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing One hot Encoding to convert multi-valued features to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'], prefix='sales')],axis='columns')\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'], prefix='salary')],axis='columns')\n",
    "Z = Z.drop(['sales','salary'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy( df ):\n",
    "    Class = df.keys()[-1]\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate entropy of specific attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_entropy_attr( df,  attribute ):\n",
    "    Class = df.keys()[-1]\n",
    "    target_variables = df[Class].unique()  \n",
    "    variables = df[attribute].unique()\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        fraction2 = float(den)/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate IG of all feature and select attribute with maximum IG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_to_select(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        IG.append(get_entropy(df)-get_entropy_attr(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node, value):\n",
    "    return df[df[node] == value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node structure of Decision Tree ( Binary Tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.positive = 0\n",
    "        self.negative = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Build Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns) == 1:\n",
    "        return None\n",
    "    node_to_split = attr_to_select(df)\n",
    "    \n",
    "    root = Node(node_to_split)\n",
    "    root.positive = len( df[df['left']==1]['left'] )\n",
    "    root.negative = len( df[df['left']==0]['left'] )\n",
    "    \n",
    "    subtable0 = get_subtable(df,node_to_split,0)\n",
    "    subtable1 = get_subtable(df,node_to_split,1)\n",
    "    \n",
    "    subtable0 = subtable0.drop(node_to_split,axis=1)\n",
    "    subtable1 = subtable1.drop(node_to_split,axis=1)\n",
    "    \n",
    "    clValue0,counts0 = np.unique(subtable0['left'],return_counts=True)\n",
    "    clValue1,counts1 = np.unique(subtable1['left'],return_counts=True)\n",
    "        \n",
    "    if len(counts0)>1:\n",
    "        root.left = build_Tree(subtable0)\n",
    "    if len(counts1)>1:\n",
    "        root.right = build_Tree(subtable1)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_Tree(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to predict class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,Y1):\n",
    "    if root == None:\n",
    "        return None\n",
    "    try:\n",
    "        if root.right==None and root.left==None:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if root.right==None and df[root.feature] == 1:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return \n",
    "        if root.left == None and df[root.feature] == 0:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "        \n",
    "        if df[root.feature]==0:\n",
    "            rec_predict(df,root.left,Y1)\n",
    "        else:\n",
    "            rec_predict(df,root.right,Y1)\n",
    "    except KeyError:\n",
    "        if root.left == None:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "        rec_predict(df,root.left,Y1)\n",
    "        \n",
    "def predict(df,root,Y1):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1700    0]\n",
      " [ 548    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1700\n",
      "           1       0.00      0.00      0.00       548\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2248\n",
      "   macro avg       0.38      0.50      0.43      2248\n",
      "weighted avg       0.57      0.76      0.65      2248\n",
      "\n",
      "0.7562277580071174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushit/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y1=[]\n",
    "predict(X_test,root,Y1)\n",
    "print confusion_matrix(Y_test,Y1)\n",
    "print classification_report(Y_test,Y1)\n",
    "print accuracy_score(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbuilt scikit learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1700    0]\n",
      " [ 548    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1700\n",
      "           1       0.00      0.00      0.00       548\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2248\n",
      "   macro avg       0.38      0.50      0.43      2248\n",
      "weighted avg       0.57      0.76      0.65      2248\n",
      "\n",
      "0.7562277580071174\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predict = model.predict(X_test)\n",
    "\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing from sample_test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('sample_test.csv')\n",
    "\n",
    "Z_test = pd.concat([test_df,pd.get_dummies(test_df['sales'], prefix='sales')],axis='columns')\n",
    "Z_test = pd.concat([Z_test,pd.get_dummies(Z_test['salary'], prefix='salary')],axis='columns')\n",
    "Z_test = Z_test.drop(['sales','salary'],axis='columns')\n",
    "\n",
    "Out = []\n",
    "predict(Z_test, root, Out)\n",
    "print Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. to handle categorical data in Binary decision tree, they have to be encoded using one-hot encoding or other methods. \n",
    "2. using only some features of the data the result is poor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
