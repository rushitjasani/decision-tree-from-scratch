{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q-1-6.ipynb \n",
    "Explain how decision tree is suitable handle missing values(few\n",
    "attributes missing in test samples) in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When at prediction time we encounter a node in the decision tree which tests a variable A, and for that variable we have in our instance a missing value than all the possibilities are explored. Thus, for each possible subnode a prediction is made. We keep the distribution for each sub node and we add them. Finally the class chosen for prediction is the class with the biggest density value. \n",
    "\n",
    "* In simpler words if at a node we don't have an observation try both it's branches and let's say we have x+y positive samples and z+w negative samples, now the greater of those two will determine class label of the test sample. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
