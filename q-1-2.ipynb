{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q-1-2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting features and class label and dropping numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing One hot Encoding to convert multi-valued features to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 0 means row and axis= 1 means columns. \n",
    "# default is 0. \n",
    "Z = pd.concat([X,pd.get_dummies(X['sales'], prefix='sales')],axis='columns')\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'], prefix='salary')],axis='columns')\n",
    "Z = Z.drop(['sales','salary'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "X_test_copy = X_test.copy(deep=True)\n",
    "df1 = pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy( df ):\n",
    "    Class = df.keys()[-1]\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy\n",
    "\n",
    "#TESTING OF ENTROPY FUNC\n",
    "# c = pd.DataFrame({'rushit' : [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,11,1,1,1,1,1,1,1,1,1,1]})\n",
    "# x_ent = get_entropy(c.rushit)\n",
    "# x_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding entropy of given attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_entropy_attr( df,  attribute ):\n",
    "    Class = df.keys()[-1]\n",
    "    target_variables = df[Class].unique()  \n",
    "    variables = df[attribute].unique()\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        fraction2 = float(den)/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting attribute with highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_to_select(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        IG.append(get_entropy(df)-get_entropy_attr(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dividing table in subtable by given value and attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node, value):\n",
    "    return df[df[node] == value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding information gain by splitting value of attr at splitting point val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ent = get_entropy(df1)\n",
    "def find_IG( df, val, attr ):\n",
    "    left = df[df[attr] < val ].reset_index(drop=True)\n",
    "    right = df[df[attr] >= val ].reset_index(drop=True)\n",
    "    left_ent = get_entropy(left)\n",
    "    right_ent = get_entropy(right)\n",
    "    return class_ent - ((float(len(left))/(len(df)+eps) * left_ent)+( float(len(right))/(len(df)+eps) * right_ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding maximum split point by trying all possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_numerical( attr , Y , attr_name):\n",
    "    max_ig = 0\n",
    "    max_split = None\n",
    "    pair = pd.concat([attr, Y], axis='columns')\n",
    "    pair = pair.sort_values(by =attr_name).reset_index()\n",
    "    for i in xrange( len(attr)-1):\n",
    "#         print i, pair[attr_name][i] , pair[attr_name][i+1]\n",
    "        if pair['left'][i] != pair['left'][i+1]:\n",
    "            cur_ig = find_IG( pair, float(pair[attr_name][i] + pair[attr_name][i+1])/2 , attr_name )\n",
    "            if cur_ig > max_ig:\n",
    "                max_ig = cur_ig\n",
    "                max_split =  float(pair[attr_name][i] + pair[attr_name][i+1])/2\n",
    "    return max_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing data in actual dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_actual( df, val, attr ):\n",
    "    df.loc[df[attr] < val, attr ] = 0\n",
    "    df.loc[df[attr] >= val, attr ] = 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting dictionary of splitting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.46499999999999997, 'last_evaluation': 0.58, 'average_montly_hours': 274.5, 'time_spend_company': 3.0, 'number_project': 2.5}\n"
     ]
    }
   ],
   "source": [
    "num_attr = [ 'number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_dict = {}\n",
    "for attr in num_attr:\n",
    "    split_val = split_numerical(df1[attr], df1['left'],attr)\n",
    "    split_dict[attr] = split_val\n",
    "print split_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing data with numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,split_dict):\n",
    "    for key,value in split_dict.iteritems():\n",
    "        change_actual(df, value, key)\n",
    "\n",
    "preprocess(df1,split_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree node structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.positive = 0\n",
    "        self.negative = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns) == 1:\n",
    "        return None\n",
    "    node_to_split = attr_to_select(df)\n",
    "    \n",
    "    root = Node(node_to_split)\n",
    "    root.positive = len( df[df['left']==1]['left'] )\n",
    "    root.negative = len( df[df['left']==0]['left'] )\n",
    "    \n",
    "    subtable0 = get_subtable(df,node_to_split,0)\n",
    "    subtable1 = get_subtable(df,node_to_split,1)\n",
    "    \n",
    "    subtable0 = subtable0.drop(node_to_split,axis=1)\n",
    "    subtable1 = subtable1.drop(node_to_split,axis=1)\n",
    "    \n",
    "    clValue0,counts0 = np.unique(subtable0['left'],return_counts=True)\n",
    "    clValue1,counts1 = np.unique(subtable1['left'],return_counts=True)\n",
    "        \n",
    "    if len(counts0)>1:\n",
    "        root.left = build_Tree(subtable0)\n",
    "    if len(counts1)>1:\n",
    "        root.right = build_Tree(subtable1)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction od data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,Y1):\n",
    "    if root == None:\n",
    "        return None\n",
    "    try:\n",
    "        if root.right==None and root.left==None:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if root.right==None and df[root.feature] == 1:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return \n",
    "        if root.left == None and df[root.feature] == 0:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "        \n",
    "        if df[root.feature]==0:\n",
    "            rec_predict(df,root.left,Y1)\n",
    "        else:\n",
    "            rec_predict(df,root.right,Y1)\n",
    "    except KeyError:\n",
    "        if root.left == None:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "        rec_predict(df,root.left,Y1)\n",
    "        \n",
    "def predict(df,root,Y1):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_Tree(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1681   35]\n",
      " [ 219  313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1716\n",
      "           1       0.90      0.59      0.71       532\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2248\n",
      "   macro avg       0.89      0.78      0.82      2248\n",
      "weighted avg       0.89      0.89      0.88      2248\n",
      "\n",
      "0.8870106761565836\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "Yp=[]\n",
    "preprocess(X_test,split_dict)\n",
    "predict(X_test,root,Yp)\n",
    "\n",
    "print confusion_matrix(Y_test,Yp)\n",
    "print classification_report(Y_test,Yp)\n",
    "print accuracy_score(Y_test, Yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbuilt scikit learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1676   40]\n",
      " [  30  502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1716\n",
      "           1       0.93      0.94      0.93       532\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.95      0.96      0.96      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9688612099644128\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X_test_copy)\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on sample_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('sample_test.csv')\n",
    "\n",
    "Z_test = pd.concat([test_df,pd.get_dummies(test_df['sales'], prefix='sales')],axis='columns')\n",
    "Z_test = pd.concat([Z_test,pd.get_dummies(Z_test['salary'], prefix='salary')],axis='columns')\n",
    "Z_test = Z_test.drop(['sales','salary'],axis='columns')\n",
    "\n",
    "preprocess(Z_test, split_dict)\n",
    "Out = []\n",
    "predict(Z_test, root, Out)\n",
    "print Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
