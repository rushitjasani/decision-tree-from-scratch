{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q-1-3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting features and class label and dropping numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing One hot Encoding to convert multi-valued features to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 0 means row and axis= 1 means columns. \n",
    "# default is 0. \n",
    "Z = pd.concat([X,pd.get_dummies(X['sales'], prefix='sales')],axis='columns')\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'], prefix='salary')],axis='columns')\n",
    "Z = Z.drop(['sales','salary'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df_ent = pd.concat([X_train,Y_train],axis=1)\n",
    "df_gini = pd.concat([X_train,Y_train],axis=1)\n",
    "df_mis_rate = pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymodel(df1, flag ):\n",
    "    def get_impurity( df , flag ):\n",
    "        Class = df.keys()[-1]\n",
    "        if flag == 1:\n",
    "            entropy = 0\n",
    "            values = df[Class].unique()\n",
    "            for value in values:\n",
    "                fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "                entropy += -fraction*np.log2(fraction+eps)\n",
    "            return entropy\n",
    "        if flag == 2:\n",
    "            entropy = 1\n",
    "            values = df[Class].unique()\n",
    "            for value in values:\n",
    "                fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "                entropy *= fraction\n",
    "            return 2*entropy\n",
    "        if flag == 3:\n",
    "            entropy = 1\n",
    "            values = df[Class].unique()\n",
    "            for value in values:\n",
    "                fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "                entropy = min(fraction , 1-fraction)\n",
    "            return entropy\n",
    "\n",
    "    def get_impurity_attr( df,  attribute, flag ):\n",
    "        if flag == 1:\n",
    "            Class = df.keys()[-1]\n",
    "            target_variables = df[Class].unique()  \n",
    "            variables = df[attribute].unique()\n",
    "            entropy2 = 0\n",
    "            for variable in variables:\n",
    "                entropy = 0\n",
    "                for target_variable in target_variables:\n",
    "                    num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "                    den = len(df[attribute][df[attribute]==variable])\n",
    "                    fraction = num/(den+eps)\n",
    "                    entropy += -fraction*np.log2(fraction+eps)\n",
    "                fraction2 = float(den)/len(df)\n",
    "                entropy2 += -fraction2*entropy\n",
    "            return abs(entropy2)\n",
    "        if flag == 2:\n",
    "            Class = df.keys()[-1]\n",
    "            target_variables = df[Class].unique()  \n",
    "            variables = df[attribute].unique()\n",
    "            entropy2 = 0\n",
    "            for variable in variables:\n",
    "                entropy = 1\n",
    "                for target_variable in target_variables:\n",
    "                    num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "                    den = len(df[attribute][df[attribute]==variable])\n",
    "                    fraction = num/(den+eps)\n",
    "                    entropy *= fraction\n",
    "                entropy *= 2\n",
    "                fraction2 = float(den)/len(df)\n",
    "                entropy2 += fraction2*entropy\n",
    "            return entropy2\n",
    "        if flag == 3:\n",
    "            Class = df.keys()[-1]\n",
    "            target_variables = df[Class].unique()  \n",
    "            variables = df[attribute].unique()\n",
    "            entropy2 = 0\n",
    "            for variable in variables:\n",
    "                entropy = 1\n",
    "                for target_variable in target_variables:\n",
    "                    num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "                    den = len(df[attribute][df[attribute]==variable])\n",
    "                    fraction = num/(den+eps)\n",
    "                    entropy = min(fraction, 1 - fraction)\n",
    "                fraction2 = float(den)/len(df)\n",
    "                entropy2 += fraction2*entropy\n",
    "            return entropy2\n",
    "\n",
    "    def attr_to_select(df,flag):\n",
    "        Entropy_att = []\n",
    "        IG = []\n",
    "        for key in df.keys()[:-1]:\n",
    "            IG.append(get_impurity(df, flag)-get_impurity_attr(df,key, flag))\n",
    "        return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "    def get_subtable(df, node, value):\n",
    "        return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "    class_ent = get_impurity(df1, flag)\n",
    "    def find_IG( df, val, attr , flag ):\n",
    "        left = df[df[attr] < val ].reset_index(drop=True)\n",
    "        right = df[df[attr] >= val ].reset_index(drop=True)\n",
    "        left_imp = get_impurity(left, flag)\n",
    "        right_imp = get_impurity(right, flag)\n",
    "        return class_ent - ((float(len(left))/(len(df)+eps) * left_imp)+( float(len(right))/(len(df)+eps) * right_imp))\n",
    "\n",
    "    def split_numerical( attr , Y , attr_name , flag):\n",
    "        max_ig = 0\n",
    "        max_split = None\n",
    "        pair = pd.concat([attr, Y], axis='columns')\n",
    "        pair = pair.sort_values(by =attr_name).reset_index()\n",
    "        for i in xrange( len(attr)-1):\n",
    "            if pair['left'][i] != pair['left'][i+1]:\n",
    "                cur_ig = find_IG( pair, float(pair[attr_name][i] + pair[attr_name][i+1])/2 , attr_name, flag )\n",
    "                if cur_ig > max_ig:\n",
    "                    max_ig = cur_ig\n",
    "                    max_split =  float(pair[attr_name][i] + pair[attr_name][i+1])/2\n",
    "        return max_split\n",
    "\n",
    "    def change_actual( df, val, attr ):\n",
    "        df.loc[df[attr] < val, attr ] = 0\n",
    "        df.loc[df[attr] >= val, attr ] = 1\n",
    "        return\n",
    "\n",
    "    num_attr = [ 'number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "    split_dict = {}\n",
    "    for attr in num_attr:\n",
    "        split_val = split_numerical(df1[attr], df1['left'],attr, flag)\n",
    "        split_dict[attr] = split_val\n",
    "    print split_dict\n",
    "\n",
    "    def preprocess(df,split_dict):\n",
    "        for key,value in split_dict.iteritems():\n",
    "            change_actual(df, value, key)\n",
    "\n",
    "    preprocess(df1,split_dict)\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature):\n",
    "            self.feature = feature\n",
    "            self.positive = 0\n",
    "            self.negative = 0\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "\n",
    "    def build_Tree(df, flag):\n",
    "        if len(df.columns) == 1:\n",
    "            return None\n",
    "        node_to_split = attr_to_select(df,flag)\n",
    "\n",
    "        root = Node(node_to_split)\n",
    "        root.positive = len( df[df['left']==1]['left'] )\n",
    "        root.negative = len( df[df['left']==0]['left'] )\n",
    "\n",
    "        subtable0 = get_subtable(df,node_to_split,0)\n",
    "        subtable1 = get_subtable(df,node_to_split,1)\n",
    "\n",
    "        subtable0 = subtable0.drop(node_to_split,axis=1)\n",
    "        subtable1 = subtable1.drop(node_to_split,axis=1)\n",
    "\n",
    "        clValue0,counts0 = np.unique(subtable0['left'],return_counts=True)\n",
    "        clValue1,counts1 = np.unique(subtable1['left'],return_counts=True)\n",
    "\n",
    "        if len(counts0)>1:\n",
    "            root.left = build_Tree(subtable0,flag)\n",
    "        if len(counts1)>1:\n",
    "            root.right = build_Tree(subtable1,flag)\n",
    "\n",
    "        return root\n",
    "\n",
    "    def rec_predict(df,root,Y1):\n",
    "        if root == None:\n",
    "            return None\n",
    "\n",
    "        if root.right==None and root.left==None:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if root.right==None and df[root.feature] == 1:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return \n",
    "        if root.left == None and df[root.feature] == 0:\n",
    "            Y1.append(1 if root.positive > root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if df[root.feature]==0:\n",
    "            rec_predict(df,root.left,Y1)\n",
    "        else:\n",
    "            rec_predict(df,root.right,Y1)\n",
    "\n",
    "    def predict(df,root,Y1):\n",
    "        for col,row in df.iterrows():\n",
    "            rec_predict(row,root,Y1)\n",
    "\n",
    "    root = build_Tree(df1,flag)\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    X_test_copy = X_test.copy(deep=True)\n",
    "    Yp=[]\n",
    "    preprocess(X_test_copy,split_dict)\n",
    "    predict(X_test_copy,root,Yp)\n",
    "\n",
    "    print confusion_matrix(Y_test,Yp)\n",
    "    print classification_report(Y_test,Yp)\n",
    "    print accuracy_score(Y_test, Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.46499999999999997, 'last_evaluation': 0.58, 'average_montly_hours': 287.5, 'time_spend_company': 3.0, 'number_project': 2.5}\n",
      "[[1642   61]\n",
      " [ 241  304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      1703\n",
      "           1       0.83      0.56      0.67       545\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2248\n",
      "   macro avg       0.85      0.76      0.79      2248\n",
      "weighted avg       0.86      0.87      0.86      2248\n",
      "\n",
      "0.8656583629893239\n"
     ]
    }
   ],
   "source": [
    "mymodel(df_ent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.46499999999999997, 'last_evaluation': 0.58, 'average_montly_hours': 275.0, 'time_spend_company': 3.0, 'number_project': 2.5}\n",
      "[[1664   39]\n",
      " [ 215  330]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      1703\n",
      "           1       0.89      0.61      0.72       545\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2248\n",
      "   macro avg       0.89      0.79      0.83      2248\n",
      "weighted avg       0.89      0.89      0.88      2248\n",
      "\n",
      "0.8870106761565836\n"
     ]
    }
   ],
   "source": [
    "mymodel(df_gini, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.11499999999999999, 'last_evaluation': 1.0, 'average_montly_hours': 275.0, 'time_spend_company': 4.0, 'number_project': 2.5}\n",
      "[[1625   78]\n",
      " [ 280  265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1703\n",
      "           1       0.77      0.49      0.60       545\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2248\n",
      "   macro avg       0.81      0.72      0.75      2248\n",
      "weighted avg       0.83      0.84      0.83      2248\n",
      "\n",
      "0.8407473309608541\n"
     ]
    }
   ],
   "source": [
    "mymodel(df_mis_rate, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
