{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q-1-2.py\n",
    "\n",
    "Train the decision tree with categorical and numerical features. Report precision, recall, f1 score and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### steps\n",
    "\n",
    "1. read data\n",
    "2. apply onehot encoding ( to handle categorical Data )\n",
    "3. divide dataset in 80:20 for training and validation.\n",
    "4. build decision tree using build_tree and helper functions for entropy and attribite_to_select etc\n",
    "   ```\n",
    "   for numerical features\n",
    "   4.1 sort them on feature values along with class labels\n",
    "   4.2 calculate IG on average of feature values where class value differs\n",
    "   4.3 select point giving highest gain as the point to split that numericl feature\n",
    "   ```\n",
    "5. apply predict method to predict class label and use inbuilt functions to calculate confusion matrix, classification report and accuracy score.\n",
    "6. calculate the same measures using inbuilt scikit-learn decision tree to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting features and class label and dropping numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing One hot Encoding to convert multi-valued features to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 0 means row and axis= 1 means columns. \n",
    "# default is 0. \n",
    "Z = pd.concat([X,pd.get_dummies(X['sales'], prefix='sales')],axis='columns')\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'], prefix='salary')],axis='columns')\n",
    "Z = Z.drop(['sales','salary'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "X_test_copy = X_test.copy(deep=True)\n",
    "df1 = pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy( df ):\n",
    "    Class = df.keys()[-1]\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding entropy of given attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_entropy_attr( df,  attribute ):\n",
    "    Class = df.keys()[-1]\n",
    "    target_variables = df[Class].unique()  \n",
    "    variables = df[attribute].unique()\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        fraction2 = float(den)/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrs = [ 'number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company'] \n",
    "split_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dividing table in subtable by given value and attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node, value):\n",
    "    return df[df[node] == value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding information gain by splitting value of attr at splitting point val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_IG( df, val, attr ):\n",
    "    class_ent = get_entropy(df)\n",
    "    left = df[df[attr] < val ].reset_index(drop=True)\n",
    "    right = df[df[attr] >= val ].reset_index(drop=True)\n",
    "    left_ent = get_entropy(left)\n",
    "    right_ent = get_entropy(right)\n",
    "    return class_ent - ((float(len(left))/(len(df)+eps) * left_ent)+( float(len(right))/(len(df)+eps) * right_ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding maximum split point by trying all possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_numerical( attr , Y , attr_name):\n",
    "    max_ig = 0\n",
    "    max_split = None\n",
    "    pair = pd.concat([attr, Y], axis='columns')\n",
    "    pair = pair.sort_values(by =attr_name).reset_index()\n",
    "    myset = set()\n",
    "    for i in xrange( len(attr)-1):\n",
    "        if pair['left'][i] != pair['left'][i+1] and  (float(pair[attr_name][i] + pair[attr_name][i+1])/2) not in myset:\n",
    "            myset.add(float(pair[attr_name][i] + pair[attr_name][i+1])/2)\n",
    "            cur_ig = find_IG( pair, float(pair[attr_name][i] + pair[attr_name][i+1])/2 , attr_name )\n",
    "            if cur_ig > max_ig:\n",
    "                max_ig = cur_ig\n",
    "                max_split =  float(pair[attr_name][i] + pair[attr_name][i+1])/2\n",
    "    return max_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting attribute with highest information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_to_select(df):\n",
    "    num_attr = [ i for i in df.columns if i in num_attrs]\n",
    "    for attr in num_attr:\n",
    "        split_val = split_numerical(df[attr], df['left'],attr)\n",
    "        split_dict[attr] = split_val\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        IG.append(get_entropy(df)-get_entropy_attr(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing data in actual dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def change_actual( df, val, attr ):\n",
    "    df.loc[df[attr] < val, attr ] = 0\n",
    "    df.loc[df[attr] >= val, attr ] = 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting dictionary of splitting points"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_attr = [ 'number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_dict = {}\n",
    "for attr in num_attr:\n",
    "    split_val = split_numerical(df1[attr], df1['left'],attr)\n",
    "    split_dict[attr] = split_val\n",
    "print split_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing data with numerical features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess(df,split_dict):\n",
    "    for key,value in split_dict.iteritems():\n",
    "        change_actual(df, value, key)\n",
    "\n",
    "preprocess(df1,split_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree node structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.split_val = 0\n",
    "        self.positive = 0\n",
    "        self.negative = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns) == 1:\n",
    "        return None\n",
    "    node_to_split = attr_to_select(df)\n",
    "    \n",
    "    root = Node(node_to_split)\n",
    "    subtable0 = []\n",
    "    subtable1 = []\n",
    "    if node_to_split in num_attrs:\n",
    "        split_point = split_dict[node_to_split]\n",
    "        \n",
    "        root.split_val = split_point\n",
    "        root.positive = len( df[df['left'] >= split_point]['left'] )\n",
    "        root.negative = len( df[df['left'] <  split_point]['left'] )\n",
    "        \n",
    "        subtable0 = df[df[node_to_split] < split_point].reset_index(drop=True)\n",
    "        subtable1 = df[df[node_to_split] >= split_point].reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        root.positive = len( df[df['left']==1]['left'] )\n",
    "        root.negative = len( df[df['left']==0]['left'] )\n",
    "        \n",
    "        subtable0 = get_subtable(df,node_to_split,0)\n",
    "        subtable1 = get_subtable(df,node_to_split,1)\n",
    "    \n",
    "    \n",
    "    subtable0 = subtable0.drop(node_to_split,axis=1)\n",
    "    subtable1 = subtable1.drop(node_to_split,axis=1)\n",
    "    \n",
    "    clValue0,counts0 = np.unique(subtable0['left'],return_counts=True)\n",
    "    clValue1,counts1 = np.unique(subtable1['left'],return_counts=True)\n",
    "        \n",
    "    if len(counts0)>1:\n",
    "        root.left = build_Tree(subtable0)\n",
    "    if len(counts1)>1:\n",
    "        root.right = build_Tree(subtable1)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction od data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,Y1):\n",
    "    if root == None:\n",
    "        return None\n",
    "        \n",
    "    if root.feature in num_attrs:\n",
    "        try:\n",
    "            if root.right==None and root.left==None:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.right==None and df[root.feature] >= root.split_val:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return \n",
    "            if root.left == None and df[root.feature] < root.split_val:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if df[root.feature]< root.split_val:\n",
    "                rec_predict(df,root.left,Y1)\n",
    "            else:\n",
    "                rec_predict(df,root.right,Y1)\n",
    "        except KeyError:\n",
    "            if root.left == None:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "            rec_predict(df,root.left,Y1)\n",
    "    else:\n",
    "        try:\n",
    "            if root.right==None and root.left==None:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.right==None and df[root.feature] == 1:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return \n",
    "            if root.left == None and df[root.feature] == 0:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if df[root.feature]==0:\n",
    "                rec_predict(df,root.left,Y1)\n",
    "            else:\n",
    "                rec_predict(df,root.right,Y1)\n",
    "        except KeyError:\n",
    "            if root.left == None:\n",
    "                Y1.append(1 if root.positive > root.negative else 0)\n",
    "                return\n",
    "            rec_predict(df,root.left,Y1)\n",
    "        \n",
    "def predict(df,root,Y1):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_Tree(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1709   42]\n",
      " [  53  444]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1751\n",
      "           1       0.91      0.89      0.90       497\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2248\n",
      "   macro avg       0.94      0.93      0.94      2248\n",
      "weighted avg       0.96      0.96      0.96      2248\n",
      "\n",
      "0.9577402135231317\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "Yp=[]\n",
    "# preprocess(X_test,split_dict)\n",
    "predict(X_test,root,Yp)\n",
    "\n",
    "print confusion_matrix(Y_test,Yp)\n",
    "print classification_report(Y_test,Yp)\n",
    "print accuracy_score(Y_test, Yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbuilt scikit learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1709   42]\n",
      " [  25  472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1751\n",
      "           1       0.92      0.95      0.93       497\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.95      0.96      0.96      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9701957295373665\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X_test_copy)\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on sample_test.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df = pd.read_csv('../testing.csv')\n",
    "Y_act = test_df.left\n",
    "test_df = test_df.drop(['left'],axis='columns')\n",
    "\n",
    "Z_test = pd.concat([test_df,pd.get_dummies(test_df['sales'], prefix='sales')],axis='columns')\n",
    "Z_test = pd.concat([Z_test,pd.get_dummies(Z_test['salary'], prefix='salary')],axis='columns')\n",
    "Z_test = Z_test.drop(['sales','salary'],axis='columns')\n",
    "\n",
    "Out = []\n",
    "predict(Z_test, root, Out)\n",
    "print confusion_matrix(Out,Y_act)\n",
    "print classification_report(Out,Y_act)\n",
    "print accuracy_score(Out,Y_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "1. using NUmerical and categorical features improved result over categorical features\n",
    "2. to handle numerical features best split point is to be found on every node of the tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
